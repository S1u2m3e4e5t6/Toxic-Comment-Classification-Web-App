# ðŸ§  Toxic Comment Classification - NLP Project

Toxic Comment Classification
This project demonstrates a simple machine learning model to classify comments as toxic or non-toxic. It uses the Kaggle Toxic Comment Classification Challenge dataset.

Project Description
The goal of this project is to build a classifier that can identify toxic comments from a dataset of Wikipedia edits. The project involves:

Loading and preprocessing the dataset.
Using TF-IDF to convert text data into numerical features.
Training a Logistic Regression model to classify comments.
Evaluating the model's performance.
Setup and Installation
To run this code, you will need a Google Colab environment or a local Python environment with the necessary libraries installed.

Using Google Colab
The easiest way to run this project is in Google Colab.

Open this notebook in Google Colab.
You will need to download the dataset from Kaggle. To do this, you need a Kaggle account and an API key.
Go to your Kaggle account settings.
Under the API section, click "Create New API Token". This will download a kaggle.json file.
In the Colab file browser (left sidebar), upload the kaggle.json file.
Run all the code cells in the notebook sequentially.
Local Environment
If you prefer to run this locally, you will need Python installed.

Clone this repository.
Install the required libraries:





